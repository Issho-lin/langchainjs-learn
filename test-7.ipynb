{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = { env };\n",
    "// process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate, ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import {\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\";\n",
    "import { ChatMessageHistory, getBufferString } from \"langchain/memory\";\n",
    "\n",
    "const summaryPrompt = PromptTemplate.fromTemplate(\n",
    "  `\n",
    "请基于已有摘要和新增对话内容，生成一个连贯的渐进式更新摘要。新摘要需整合历史信息与最新对话要点，保持语义完整性和上下文连贯性。\n",
    "\n",
    "当前摘要：\n",
    "{summary}\n",
    "\n",
    "新增对话内容： \n",
    "{new_lines}\n",
    "`\n",
    ");\n",
    "\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "  summaryPrompt,\n",
    "  summaryModel,\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "// const newSummary = await summaryChain.invoke({\n",
    "//   summary: \"我很喜欢旅行\",\n",
    "//   new_lines: \"我昨天晚上去了北京，很开心\",\n",
    "// });\n",
    "\n",
    "// console.log(newSummary);\n",
    "\n",
    "// const summary2 = await summaryChain.invoke({\n",
    "//   summary: newSummary,\n",
    "//   new_lines: \"我计划今年冬天的时候再去一次\",\n",
    "// });\n",
    "\n",
    "// console.log(summary2);\n",
    "\n",
    "// await summaryChain.invoke({\n",
    "//   summary: summary2,\n",
    "//   new_lines: \"我想去看天安门升旗，什么时候去比较好？\",\n",
    "// });\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"你是一个机器人助理，请尽你所能回答用户的问题，这里有一个关于用户的摘要：{summary}\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "// // 记录会话历史摘要\n",
    "let historySummary = \"\";\n",
    "// // 新增对话内容\n",
    "// let newLines = \"\";\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "const chatChain = RunnableSequence.from([\n",
    "  {\n",
    "    input: new RunnablePassthrough({\n",
    "      func: (input) => {\n",
    "        // console.log(\"用户提问加入会话历史\", input);\n",
    "        // newLines = input;\n",
    "        history.addUserMessage(input);\n",
    "      },\n",
    "    }),\n",
    "  },\n",
    "  // 合并总结摘要和用户输入，传递给prompt\n",
    "  RunnablePassthrough.assign({\n",
    "    summary: () => historySummary,\n",
    "  }),\n",
    "  // 打印prompt输入参数，直通管道，与 new RunnablePassthrough() 效果一致\n",
    "  (input) => {\n",
    "    console.log(\"input\", input);\n",
    "    return input;\n",
    "  },\n",
    "  chatPrompt,\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "  new RunnablePassthrough({\n",
    "    func: async (input) => {\n",
    "      // console.log(\"机器人回答加入会话历史\", input);\n",
    "      history.addAIChatMessage(input);\n",
    "      const messages = await history.getMessages();\n",
    "      // console.log(\"messages\", messages);\n",
    "      const new_lines = getBufferString(messages);\n",
    "      // console.log(\"new_lines\", new_lines);\n",
    "      // 更新总结摘要\n",
    "      const newSummary = await summaryChain.invoke({\n",
    "        summary: historySummary,\n",
    "        new_lines: new_lines,\n",
    "      });\n",
    "      history.clear();\n",
    "      historySummary = newSummary;\n",
    "    },\n",
    "  }),\n",
    "]);\n",
    "\n",
    "// await chatChain.invoke(\"我想出去玩, 你推荐去哪里玩？\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import {\n",
    "  ConversationSummaryMemory,\n",
    "  ConversationSummaryBufferMemory,\n",
    "} from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  verbose: false,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const memory = new ConversationSummaryMemory({\n",
    "  memoryKey: \"summary\",\n",
    "  llm: summaryModel,\n",
    "});\n",
    "// const memory = new ConversationSummaryBufferMemory({\n",
    "//   memoryKey: \"summary\",\n",
    "//   llm: summaryModel,\n",
    "//   maxTokenLimit: 200\n",
    "// });\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"你是鲁迅，请尽你所能回答用户的问题，以你的散文风格来回答，这里有一个关于用户的摘要：{summary}\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "const chain = new ConversationChain({\n",
    "  llm: chatModel,\n",
    "  memory,\n",
    "  prompt: chatPrompt,\n",
    "  verbose: false,\n",
    "  outputKey: \"content\",\n",
    "});\n",
    "const chatChain = chain.pipe(new StringOutputParser());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const rst1 = await chatChain.invoke({ input: \"我昨天晚上去了北京，很开心\" });\n",
    "console.log(rst1 + \"\\n\");\n",
    "// const rst2 = await chatChain.invoke({ input: \"去爬了长城\" });\n",
    "// console.log(rst2);\n",
    "const rst3 = await chatChain.invoke({ input: \"我计划今年冬天的时候再去一次\" });\n",
    "console.log(rst3 + \"\\n\");\n",
    "const rst4 = await chatChain.invoke({ input: \"你知道我说的是去哪个城市吗\" });\n",
    "console.log(rst4 + \"\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  请你遵循以下的指令，并以老北京的说话风格来回答用户的问题。\n",
      "  指令如下：\n",
      "  You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import {\n",
    "  EntityMemory,\n",
    "  ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "} from \"langchain/memory\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "// console.log(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template);\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  verbose: false,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const memory = new EntityMemory({\n",
    "  llm: summaryModel,\n",
    "  chatHistoryKey: \"history\",\n",
    "  entitiesKey: \"entities\",\n",
    "});\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "// console.log(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template);\n",
    "\n",
    "// const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "//   [\n",
    "//     \"system\",\n",
    "//     `\n",
    "//     你是鲁迅，请尽你所能回答用户的问题，以你的散文风格来回答。\n",
    "\n",
    "//     当前活跃实体: {entities}\n",
    "//     历史对话摘要: {history}\n",
    "//     `,\n",
    "//   ],\n",
    "//   [\"human\", \"{input}\"],\n",
    "// ]);\n",
    "\n",
    "const chatPrompt = PromptTemplate.fromTemplate(`\n",
    "  请你遵循以下的指令，并以老北京的说话风格来回答用户的问题。\n",
    "  指令如下：\n",
    "  ${ENTITY_MEMORY_CONVERSATION_TEMPLATE.template}\n",
    "  `);\n",
    "\n",
    "console.log(chatPrompt.template);\n",
    "\n",
    "const chain = new ConversationChain({\n",
    "  llm: chatModel,\n",
    "  memory,\n",
    "  prompt: chatPrompt,\n",
    "  verbose: false,\n",
    "  outputKey: \"content\",\n",
    "});\n",
    "const chatChain = chain.pipe(new StringOutputParser());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rst1---哎呀，小明啊，你今年18岁啦！这年纪可真是青春年少，正是好时候呢。有什么新鲜事儿想和我这个老北京人分享不？\n",
      "\n",
      "rst2---哎呀，小明啊，你说的这家有面啊，老北京人可不太熟悉。不过听你这么一说，我倒是想起来了，原来还有这么一家卖方便面的互联网公司。不过现在市面上更多的是一些知名的方便面品牌，比如康师傅、统一这些，不知道这家有面公司在市场上怎么样？\n",
      "\n",
      "rst3---哎呀，您这是问到我了。我是小明，今年18岁，是个地地道道的北京小哥儿。有面这家公司啊，虽然我这个小京片子不太熟悉，但听说他们是一家互联网公司，专门卖方便面的。现在的方便面市场可是百花齐放，康师傅、统一这些大牌都挺有名的。不过有面这个公司具体怎么样，我还真不太清楚，您得问问那些懂行的才行。咱们北京人讲究的是吃，您要是想了解吃的，我可是能给您讲上一整天。\n",
      "\n",
      "rst4---哎呀，小明啊，你问的这个问题嘛，prompt就是咱们对话中的一种提示，就像是我们老北京人聊天时候的开场白，告诉人家你要说啥。比如说，我一开始就告诉你“我叫小明，今年18岁”，这就是一个prompt，告诉人家我就是小明，今年18岁。在网络世界里，prompt就像是给机器发出的一道指令，告诉它你要让它回答啥问题。这样，机器就能根据你的指令，给出相应的回答啦。不过，您要是有啥具体的问题，尽管问我，我老北京人虽然文化不多，但也乐意帮您解答。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const rst1 = await chatChain.invoke({ input: \"我叫小明，今年 18 岁\" });\n",
    "console.log(\"rst1---\" + rst1 + \"\\n\");\n",
    "const rst2 = await chatChain.invoke({\n",
    "  input: \"有面 是一家互联网公司，主要是售卖方便面的公司\",\n",
    "});\n",
    "console.log(\"rst2---\" + rst2 + \"\\n\");\n",
    "const rst3 = await chatChain.invoke({ input: \"介绍小明和有面\" });\n",
    "console.log(\"rst3---\" + rst3 + \"\\n\");\n",
    "\n",
    "const rst4 = await chatChain.invoke({ input: \"你知道prompt代表什么吗\" });\n",
    "console.log(\"rst4---\" + rst4 + \"\\n\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
