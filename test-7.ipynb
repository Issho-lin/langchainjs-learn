{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = { env };\n",
    "// process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate, ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import {\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\";\n",
    "import { ChatMessageHistory, getBufferString } from \"langchain/memory\";\n",
    "\n",
    "const summaryPrompt = PromptTemplate.fromTemplate(\n",
    "  `\n",
    "请基于已有摘要和新增对话内容，生成一个连贯的渐进式更新摘要。新摘要需整合历史信息与最新对话要点，保持语义完整性和上下文连贯性。\n",
    "\n",
    "当前摘要：\n",
    "{summary}\n",
    "\n",
    "新增对话内容： \n",
    "{new_lines}\n",
    "`\n",
    ");\n",
    "\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "  summaryPrompt,\n",
    "  summaryModel,\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "// const newSummary = await summaryChain.invoke({\n",
    "//   summary: \"我很喜欢旅行\",\n",
    "//   new_lines: \"我昨天晚上去了北京，很开心\",\n",
    "// });\n",
    "\n",
    "// console.log(newSummary);\n",
    "\n",
    "// const summary2 = await summaryChain.invoke({\n",
    "//   summary: newSummary,\n",
    "//   new_lines: \"我计划今年冬天的时候再去一次\",\n",
    "// });\n",
    "\n",
    "// console.log(summary2);\n",
    "\n",
    "// await summaryChain.invoke({\n",
    "//   summary: summary2,\n",
    "//   new_lines: \"我想去看天安门升旗，什么时候去比较好？\",\n",
    "// });\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"你是一个机器人助理，请尽你所能回答用户的问题，这里有一个关于用户的摘要：{summary}\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "// // 记录会话历史摘要\n",
    "let historySummary = \"\";\n",
    "// // 新增对话内容\n",
    "// let newLines = \"\";\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "const chatChain = RunnableSequence.from([\n",
    "  {\n",
    "    input: new RunnablePassthrough({\n",
    "      func: (input) => {\n",
    "        // console.log(\"用户提问加入会话历史\", input);\n",
    "        // newLines = input;\n",
    "        history.addUserMessage(input);\n",
    "      },\n",
    "    }),\n",
    "  },\n",
    "  // 合并总结摘要和用户输入，传递给prompt\n",
    "  RunnablePassthrough.assign({\n",
    "    summary: () => historySummary,\n",
    "  }),\n",
    "  // 打印prompt输入参数，直通管道，与 new RunnablePassthrough() 效果一致\n",
    "  (input) => {\n",
    "    console.log(\"input\", input);\n",
    "    return input;\n",
    "  },\n",
    "  chatPrompt,\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "  new RunnablePassthrough({\n",
    "    func: async (input) => {\n",
    "      // console.log(\"机器人回答加入会话历史\", input);\n",
    "      history.addAIChatMessage(input);\n",
    "      const messages = await history.getMessages();\n",
    "      // console.log(\"messages\", messages);\n",
    "      const new_lines = getBufferString(messages);\n",
    "      // console.log(\"new_lines\", new_lines);\n",
    "      // 更新总结摘要\n",
    "      const newSummary = await summaryChain.invoke({\n",
    "        summary: historySummary,\n",
    "        new_lines: new_lines,\n",
    "      });\n",
    "      history.clear();\n",
    "      historySummary = newSummary;\n",
    "    },\n",
    "  }),\n",
    "]);\n",
    "\n",
    "// await chatChain.invoke(\"我想出去玩, 你推荐去哪里玩？\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import {\n",
    "  ConversationSummaryMemory,\n",
    "  ConversationSummaryBufferMemory,\n",
    "} from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  verbose: false,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const memory = new ConversationSummaryMemory({\n",
    "  memoryKey: \"summary\",\n",
    "  llm: summaryModel,\n",
    "});\n",
    "// const memory = new ConversationSummaryBufferMemory({\n",
    "//   memoryKey: \"summary\",\n",
    "//   llm: summaryModel,\n",
    "//   maxTokenLimit: 200\n",
    "// });\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"你是鲁迅，请尽你所能回答用户的问题，以你的散文风格来回答，这里有一个关于用户的摘要：{summary}\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "const chain = new ConversationChain({\n",
    "  llm: chatModel,\n",
    "  memory,\n",
    "  prompt: chatPrompt,\n",
    "  verbose: false,\n",
    "  outputKey: \"content\",\n",
    "});\n",
    "const chatChain = chain.pipe(new StringOutputParser());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const rst1 = await chatChain.invoke({ input: \"我昨天晚上去了北京，很开心\" });\n",
    "console.log(rst1 + \"\\n\");\n",
    "// const rst2 = await chatChain.invoke({ input: \"去爬了长城\" });\n",
    "// console.log(rst2);\n",
    "const rst3 = await chatChain.invoke({ input: \"我计划今年冬天的时候再去一次\" });\n",
    "console.log(rst3 + \"\\n\");\n",
    "const rst4 = await chatChain.invoke({ input: \"你知道我说的是去哪个城市吗\" });\n",
    "console.log(rst4 + \"\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  请你遵循以下的指令，并以老舍的散文风格来回答用户的问题。\n",
      "  指令如下：\n",
      "  You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import {\n",
    "  EntityMemory,\n",
    "  ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "} from \"langchain/memory\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "// console.log(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template);\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  verbose: false,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const memory = new EntityMemory({\n",
    "  llm: summaryModel,\n",
    "  chatHistoryKey: \"history\",\n",
    "  entitiesKey: \"entities\",\n",
    "});\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "// console.log(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template);\n",
    "\n",
    "// const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "//   [\n",
    "//     \"system\",\n",
    "//     `\n",
    "//     你是鲁迅，请尽你所能回答用户的问题，以你的散文风格来回答。\n",
    "\n",
    "//     当前活跃实体: {entities}\n",
    "//     历史对话摘要: {history}\n",
    "//     `,\n",
    "//   ],\n",
    "//   [\"human\", \"{input}\"],\n",
    "// ]);\n",
    "\n",
    "const chatPrompt = PromptTemplate.fromTemplate(`\n",
    "  请你遵循以下的指令，并以鲁迅的散文风格来回答用户的问题。\n",
    "  指令如下：\n",
    "  ${ENTITY_MEMORY_CONVERSATION_TEMPLATE.template}\n",
    "  `);\n",
    "\n",
    "console.log(chatPrompt.template);\n",
    "\n",
    "const chain = new ConversationChain({\n",
    "  llm: chatModel,\n",
    "  memory,\n",
    "  prompt: chatPrompt,\n",
    "  verbose: false,\n",
    "  outputKey: \"content\",\n",
    "});\n",
    "const chatChain = chain.pipe(new StringOutputParser());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明啊，十八岁正是青春年少的好时光。不知道你都做了些什么呢？是不是也在追寻着自己的梦想呢？\n",
      "\n",
      "小明啊，听你这么一说，我倒是想起了咱们中国的一家互联网公司——ABC。虽然现在关于它的信息不详，但听说它曾是一家售卖方便面的公司。哈哈，这可真是个有趣的对比，从食品到科技，经营范围变化之大，真是让人意想不到。\n",
      "\n",
      "不过，话又说回来，无论是做方便面还是互联网科技，关键都是要有自己的特色和追求。就像你一样，虽然年纪轻轻，但已经有了自己的梦想和追求，这真是让人敬佩。\n",
      "\n",
      "小明啊，希望你能一直坚持自己的梦想，勇往直前，未来一定能创造出属于自己的精彩人生！\n",
      "小明，这位年仅十八岁的青年，正如春日里的嫩芽，充满了生机与活力。他的名字简单而平凡，却承载着无数梦想与期待。有面，这个名字听起来或许陌生，但它背后的故事却颇具传奇色彩。它曾是一家互联网公司，主营业务是销售方便面，这种看似简单的食品，在它的手中焕发出不一样的光彩。如今，关于它的信息寥寥无几，仿佛被时间遗忘在角落里。然而，正是这样的神秘与未知，让人对其充满了好奇与想象。小明与有面，虽然行业不同，但他们都在各自的领域里努力前行，追求着自己的梦想。\n",
      "\n",
      "Prompt，这个词儿，在咱们日常生活中并不陌生。它就像是一盏指路明灯，能指引我们前进的方向。在写作或者回答问题时，给AI一个明确的提示，它就能根据这个提示，结合它所学习到的知识和算法，生成符合我们期望的文本。简而言之，Prompt就是引导AI输出特定内容和风格的那根弦。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const rst1 = await chatChain.invoke({ input: \"我叫小明，今年 18 岁\" });\n",
    "console.log(rst1 + \"\\n\");\n",
    "const rst2 = await chatChain.invoke({\n",
    "  input: \"ABC 是一家互联网公司，主要是售卖方便面的公司\",\n",
    "});\n",
    "console.log(rst2);\n",
    "const rst3 = await chatChain.invoke({ input: \"介绍小明和有面\" });\n",
    "console.log(rst3 + \"\\n\");\n",
    "\n",
    "const rst4 = await chatChain.invoke({ input: \"你知道prompt代表什么吗\" });\n",
    "console.log(rst4 + \"\\n\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
