{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = { env };\n",
    "process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\n",
    "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "\n",
    "// 加载知识库\n",
    "const loader = new TextLoader(\"documents/chatbot.txt\");\n",
    "const docs = await loader.load();\n",
    "// 切分（超出LLM上下文限制）\n",
    "const splitter = new RecursiveCharacterTextSplitter({\n",
    "  chunkSize: 100,\n",
    "  chunkOverlap: 20,\n",
    "});\n",
    "\n",
    "const splitDocs = await splitter.splitDocuments(docs);\n",
    "\n",
    "// 构建 vector store\n",
    "const embeddings = new OpenAIEmbeddings({\n",
    "  model: process.env.EMBEDDING_MODEL_NAME,\n",
    "  batchSize: 20,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "// const embeddings = new OpenAIEmbeddings({\n",
    "//   configuration: {\n",
    "//     baseURL: `https://${process.env.AZURE_OPENAI_API_INSTANCE_NAME}.openai.azure.com/openai/deployments/${process.env.AZURE_EMBEDDING_MODEL_NAME}`,\n",
    "//     apiKey: process.env.AZURE_OPENAI_API_KEY,\n",
    "//     defaultQuery: {\n",
    "//       \"api-version\": process.env.AZURE_OPENAI_API_VERSION,\n",
    "//     },\n",
    "//   },\n",
    "// });\n",
    "\n",
    "const vectorstore = new MemoryVectorStore(embeddings);\n",
    "await vectorstore.addDocuments(splitDocs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"@langchain/core/prompts\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { AIMessage } from \"@langchain/core/messages\";\n",
    "import {\n",
    "  RunnableWithMessageHistory,\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\";\n",
    "import { JSONChatHistory } from \"./node/history/index.ts\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const rephrasePrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    `给定以下对话和一个后续问题，请将后续问题重述为一个独立的问题。请注意，重述的问题应该包含足够的信息，使得没有看过对话历史的人也能理解。\n",
    "    \n",
    "    `,\n",
    "  ],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\"human\", \"将这个问题重述为一个独立的问题：{question}\"],\n",
    "]);\n",
    "\n",
    "const rephraseModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  temperature: 0.2,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const rephraseChain = rephrasePrompt\n",
    "  .pipe(rephraseModel)\n",
    "  .pipe(new StringOutputParser());\n",
    "\n",
    "// const historyMessages = [\n",
    "//   new AIMessage(\"这本书是《三体前传：球状闪电》\"),\n",
    "// ];\n",
    "\n",
    "// const question = \"你觉得我的名字怎么样？\";\n",
    "\n",
    "// await rephraseChain.invoke({\n",
    "//   history: historyMessages,\n",
    "//   question,\n",
    "// });\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    `你是一个熟知内部知识库的机器人，你在回答时会引用知识库，并擅长通过自己的总结归纳，组织语言给出答案。\n",
    "并且回答时仅根据知识库和历史记录，尽可能回答用户问题，如果知识库中没有相关内容，你可以回答“原文中没有相关内容”，不要回答知识库以外的内容。\n",
    " 以下是原文中跟用户回答相关的内容：\n",
    "    {context}\n",
    "  以下是历史记录\n",
    "    {history}\n",
    "`,\n",
    "  ],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\n",
    "    \"human\",\n",
    "    `现在，你需要基于原文，回答以下问题：\n",
    "    {question}`,\n",
    "  ],\n",
    "]);\n",
    "\n",
    "// // 构建retriever\n",
    "const retriever = vectorstore.asRetriever(2);\n",
    "// const res = await retriever.invoke(\"原文中，谁提出了宏原子的假设？并详细介绍给我宏原子假设的理论\")\n",
    "\n",
    "// console.log(res)\n",
    "\n",
    "// 将获取到的关联上下文处理成纯文字\n",
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  console.log(\"documents\", documents);\n",
    "  return documents.map((document) => document.pageContent).join(\"\\n\");\n",
    "};\n",
    "\n",
    "const contextRetrieverChain = RunnableSequence.from([\n",
    "  (input) => input.question,\n",
    "  retriever,\n",
    "  convertDocsToString,\n",
    "]);\n",
    "\n",
    "const ragChain = RunnableSequence.from([\n",
    "  RunnablePassthrough.assign({\n",
    "    question: rephraseChain,\n",
    "  }),\n",
    "  RunnablePassthrough.assign({\n",
    "    context: contextRetrieverChain,\n",
    "  }),\n",
    "  new RunnablePassthrough({\n",
    "    func: (input) => {\n",
    "      console.log(\"input\", input);\n",
    "    },\n",
    "  }), // 打印一下context的内容\n",
    "  chatPrompt,\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: ragChain,\n",
    "  getMessageHistory: (sessionId) => new JSONChatHistory({ sessionId }),\n",
    "  inputMessagesKey: \"question\",\n",
    "  historyMessagesKey: \"history\",\n",
    "});\n",
    "\n",
    "// const memory = new BufferMemory({ chatHistory: history });\n",
    "\n",
    "// const chainWithHistory = new ConversationChain({\n",
    "//   memory,\n",
    "//   llm: ragChain,\n",
    "// });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chainWithHistory.invoke(\n",
    "  {\n",
    "    question: \"三体的作者是谁\",\n",
    "  },\n",
    "  {\n",
    "    configurable: { sessionId: \"test-history\" },\n",
    "  }\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
