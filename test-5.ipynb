{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a0dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = { env };\n",
    "// process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\n",
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "\n",
    "const loader = new TextLoader(\"documents/data.txt\");\n",
    "const docs = await loader.load();\n",
    "\n",
    "const splitter = new RecursiveCharacterTextSplitter({\n",
    "  chunkSize: 100,\n",
    "  chunkOverlap: 20,\n",
    "});\n",
    "\n",
    "const splitDocs = await splitter.splitDocuments(docs);\n",
    "\n",
    "const embeddings = new OpenAIEmbeddings({\n",
    "  model: process.env.EMBEDDING_MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "// embeddings\n",
    "console.log(embeddings.modelName);\n",
    "\n",
    "await embeddings.embedQuery(splitDocs[0].pageContent);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatMessageHistory } from \"langchain/memory\";\n",
    "import { HumanMessage, AIMessage } from \"@langchain/core/messages\";\n",
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const chatHistory = new ChatMessageHistory();\n",
    "\n",
    "// await chatHistory.addUserMessage('你好')\n",
    "// await chatHistory.addAIChatMessage('有什么可以帮你的？')\n",
    "\n",
    "await chatHistory.addMessage(new HumanMessage(\"hi\"));\n",
    "await chatHistory.addMessage(new AIMessage(\"What can I do for you?\"));\n",
    "\n",
    "const messages = await chatHistory.getMessages();\n",
    "\n",
    "// console.log(messages);\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"Your are a {systemText}\"],\n",
    "  new MessagesPlaceholder(\"chat_history\"),\n",
    "  [\"human\", \"{humanText}\"],\n",
    "]);\n",
    "\n",
    "const chain = prompt.pipe(chatModel);\n",
    "\n",
    "await prompt.invoke({\n",
    "  systemText: \"Assistant is a large language model\",\n",
    "  humanText: \"Hello\",\n",
    "  chat_history: messages,\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ad8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatMessageHistory } from \"langchain/memory\";\n",
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatHistory = new ChatMessageHistory();\n",
    "\n",
    "// console.log(messages);\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"Your are a chat bot\"],\n",
    "  new MessagesPlaceholder(\"chat_history\"),\n",
    "  [\"human\", \"{humanText}\"],\n",
    "]);\n",
    "\n",
    "const outputParse = new StringOutputParser();\n",
    "\n",
    "const chain = prompt.pipe(chatModel).pipe(outputParse);\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: chain,\n",
    "  getMessageHistory: () => chatHistory,\n",
    "  inputMessagesKey: \"humanText\",\n",
    "  historyMessagesKey: \"chat_history\",\n",
    "});\n",
    "\n",
    "const res1 = await chainWithHistory.invoke(\n",
    "  {\n",
    "    humanText: \"Hello, I'm Bob\",\n",
    "  },\n",
    "  {\n",
    "    configurable: { sessionId: \"none\" },\n",
    "  }\n",
    ");\n",
    "console.log(res1);\n",
    "\n",
    "await chainWithHistory.invoke(\n",
    "  {\n",
    "    humanText: \"Who am I?\",\n",
    "  },\n",
    "  {\n",
    "    configurable: { sessionId: \"none\" },\n",
    "  }\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import {\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\";\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\"你好, {name}, 我今年{age}岁了\");\n",
    "\n",
    "// await prompt.invoke({ job: '三甲医院的骨科医生', question: '如何预防半月板损伤' })\n",
    "\n",
    "// const chain = RunnableSequence.from([\n",
    "//   {\n",
    "//     name: (input) => input.name + '111'\n",
    "//   },\n",
    "//   (input) => {\n",
    "//     return { name: '李四' + input.name }\n",
    "//   },\n",
    "//   prompt,\n",
    "//   (input) => {\n",
    "//     return input.value + '222'\n",
    "//   }\n",
    "// ]);\n",
    "\n",
    "const chain = RunnableSequence.from([\n",
    "  // input直通管道\n",
    "  new RunnablePassthrough({\n",
    "    // func，可以在这里根据input做一些额外的逻辑，不影响input的传递\n",
    "    func: (input) => {\n",
    "      console.log(\"input1---\", input);\n",
    "      // 返回什么都不影响input的结构\n",
    "      return \"666\";\n",
    "    },\n",
    "  }),\n",
    "  // 合并input和额外的参数\n",
    "  RunnablePassthrough.assign({\n",
    "    age: () => {\n",
    "      return 16;\n",
    "    },\n",
    "    name: (input) => {\n",
    "      console.log(\"input2---\", input);\n",
    "      return \"王五\";\n",
    "    },\n",
    "  }),\n",
    "  {\n",
    "    abc: (input) => {\n",
    "      console.log(\"input---\", input);\n",
    "      return { ...input, name: \"李四\" };\n",
    "    },\n",
    "  },\n",
    "  (input) => {\n",
    "    console.log(\"input---\", input);\n",
    "    return input.abc;\n",
    "  },\n",
    "  prompt,\n",
    "  (input) => {\n",
    "    return { content: input.value };\n",
    "  },\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "await chain.invoke({ name: \"张三\" });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044fc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate, ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import {\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\";\n",
    "import { ChatMessageHistory, getBufferString } from \"langchain/memory\";\n",
    "\n",
    "const summaryPrompt = PromptTemplate.fromTemplate(\n",
    "  `\n",
    "请基于已有摘要和新增对话内容，生成一个连贯的渐进式更新摘要。新摘要需整合历史信息与最新对话要点，保持语义完整性和上下文连贯性。\n",
    "\n",
    "当前摘要：\n",
    "{summary}\n",
    "\n",
    "新增对话内容： \n",
    "{new_lines}\n",
    "`\n",
    ");\n",
    "\n",
    "const summaryModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "  summaryPrompt,\n",
    "  summaryModel,\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "// const newSummary = await summaryChain.invoke({\n",
    "//   summary: \"我很喜欢旅行\",\n",
    "//   new_lines: \"我昨天晚上去了北京，很开心\",\n",
    "// });\n",
    "\n",
    "// console.log(newSummary);\n",
    "\n",
    "// const summary2 = await summaryChain.invoke({\n",
    "//   summary: newSummary,\n",
    "//   new_lines: \"我计划今年冬天的时候再去一次\",\n",
    "// });\n",
    "\n",
    "// console.log(summary2);\n",
    "\n",
    "// await summaryChain.invoke({\n",
    "//   summary: summary2,\n",
    "//   new_lines: \"我想去看天安门升旗，什么时候去比较好？\",\n",
    "// });\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"你是一个机器人助理，请尽你所能回答用户的问题，这里有一个关于用户的摘要：{summary}\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "// // 记录会话历史摘要\n",
    "let historySummary = \"\";\n",
    "// // 新增对话内容\n",
    "// let newLines = \"\";\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "const chatChain = RunnableSequence.from([\n",
    "  {\n",
    "    input: new RunnablePassthrough({\n",
    "      func: (input) => {\n",
    "        // console.log(\"用户提问加入会话历史\", input);\n",
    "        // newLines = input;\n",
    "        history.addUserMessage(input);\n",
    "      },\n",
    "    }),\n",
    "  },\n",
    "  // 合并总结摘要和用户输入，传递给prompt\n",
    "  RunnablePassthrough.assign({\n",
    "    summary: () => historySummary,\n",
    "  }),\n",
    "  // 打印prompt输入参数，直通管道，与 new RunnablePassthrough() 效果一致\n",
    "  (input) => {\n",
    "    console.log(\"input\", input);\n",
    "    return input;\n",
    "  },\n",
    "  chatPrompt,\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "  new RunnablePassthrough({\n",
    "    func: async (input) => {\n",
    "      // console.log(\"机器人回答加入会话历史\", input);\n",
    "      history.addAIChatMessage(input);\n",
    "      const messages = await history.getMessages()\n",
    "      // console.log(\"messages\", messages);\n",
    "      const new_lines = getBufferString(messages)\n",
    "      // console.log(\"new_lines\", new_lines);\n",
    "      // 更新总结摘要\n",
    "      const newSummary = await summaryChain.invoke({\n",
    "        summary: historySummary,\n",
    "        new_lines: new_lines\n",
    "      });\n",
    "      history.clear();\n",
    "      historySummary = newSummary;\n",
    "    },\n",
    "  }),\n",
    "]);\n",
    "\n",
    "// await chatChain.invoke(\"我想出去玩, 你推荐去哪里玩？\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67da181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input { input: \"我昨天晚上去了北京，很开心\", summary: \"\" }\n",
      "哇，那太棒啦！北京有好多好玩的地方呢，比如故宫、长城、颐和园等等，你昨天晚上都去了哪些地方呀，有没有什么特别有意思的经历可以和我说说哦。\n",
      "\n",
      "input {\n",
      "  input: \"去爬了长城\",\n",
      "  summary: \"当前摘要：\\n\" +\n",
      "    \"新增对话内容：人类表示昨天晚上去了北京，感觉很开心。AI回应称很棒，并列举了北京诸多好玩的地方如故宫、长城、颐和园等，还询问人类昨天晚上具体去了哪些地方以及是否有特别有意思的经历。\\n\" +\n",
      "    \"更新后摘要：人类告知昨天晚上去了北京且玩得很开心，AI对此给予热情回应，提及北京的一些好玩之处，还进一步询问人类昨晚所去的具体地点及有无特别有意思的经历。\"\n",
      "}\n",
      "哇，爬长城很不错呀！长城雄伟壮观，在上面可以领略到很不一样的风景呢。那爬长城的过程中有没有什么特别有趣的事儿呀，比如遇到了很有意思的游客，或者看到了特别美的景色之类的呢？\n",
      "\n",
      "input {\n",
      "  input: \"我计划今年冬天的时候再去一次\",\n",
      "  summary: \"人类告知昨天晚上去了北京且玩得很开心，AI对此给予热情回应，提及北京的一些好玩之处，还进一步询问人类昨晚所去的具体地点及有无特别有意思的经历。随后人类回复去爬了长城，AI表示赞叹，称爬长城很不错，提及长城雄伟壮观能领略别样风景，并再次询问人类在爬长城过程中是否有遇到有意思的游客、看到特别美的景色等特别有趣的事儿。\"\n",
      "}\n",
      "哇，那太棒啦！冬天的北京也别有一番风味呢。到时候可以去看看故宫的雪景，红墙黄瓦配上皑皑白雪，超级美，就像穿越回了古代的紫禁城。还有颐和园，冬天湖面结冰后，也是很有感觉哦。\n",
      "\n",
      "那你这次冬天去北京，还是打算去爬长城呀，还是有其他想去的新地方呀？有没有特别期待在冬天的北京经历些什么有意思的事儿呢？\n",
      "\n",
      "input {\n",
      "  input: \"我想去看升旗\",\n",
      "  summary: \"人类告知昨天晚上去了北京且玩得很开心，AI热情回应并询问具体地点及有趣经历，人类回复去爬了长城，AI赞叹并进一步询问爬长城时的趣事。随后人类表示计划今年冬天再去一次北京，AI称冬天的北京别有风味，推荐可去看故宫雪景、颐和园结冰的湖面等，还询问人类此次冬天去北京是打算再爬长城还是去其他新地方，以及是否有特别期待在冬天的北京经历的有意思之事。\"\n",
      "}\n",
      "哇，去看升旗很不错呀！那场面特别壮观，很有仪式感呢。不过看升旗可得早点去占个好位置哦，尤其是冬天，天气冷，要多穿点保暖衣物呢。你打算就专门去看升旗呀，还是看完升旗再去别的地方逛逛呀？\n",
      "\n",
      "input {\n",
      "  input: \"会不会很冷\",\n",
      "  summary: \"人类告知昨天晚上去了北京且玩得很开心，AI热情回应并询问具体地点及有趣经历，人类回复去爬了长城，AI赞叹并进一步询问爬长城时的趣事。随后人类表示计划今年冬天再去一次北京，AI称冬天的北京别有风味，推荐可去看故宫雪景、颐和园结冰的湖面等，还询问人类此次冬天去北京是打算再爬长城还是去其他新地方，以及是否有特别期待在冬天的北京经历的有意思之事。接着人类表示冬天去北京想去看升旗，AI对此表示赞赏，提醒看升旗要早点去占好位置且冬天需多穿保暖衣物，并询问人类是只打算看升旗还是看完升旗后还会去别的地方逛逛。\"\n",
      "}\n",
      "冬天的北京确实挺冷的呀，尤其是早上看升旗的时候，气温会很低，所以一定要多穿些保暖的衣物，像厚羽绒服、保暖的帽子、围巾、手套这些都得备上呢。不过要是运气好赶上出太阳，中午前后可能会稍微暖和一点哦。你去看升旗的时候可得把自己裹得暖暖的呀，可别冻着啦。看完升旗之后打算再去其他地方逛逛不？\n",
      "\n",
      "input {\n",
      "  input: \"人会不会很多\",\n",
      "  summary: \"人类告知昨天晚上去了北京且玩得很开心，AI热情回应并询问具体地点及有趣经历，人类回复去爬了长城，AI赞叹并进一步询问爬长城时的趣事。随后人类表示计划今年冬天再去一次北京，AI称冬天的北京别有风味，推荐可去看故宫雪景、颐和园结冰的湖面等，还询问人类此次冬天去北京是打算再爬长城还是去其他新地方，以及是否有特别期待在冬天的北京经历的有意思之事。接着人类表示冬天去北京想去看升旗，AI对此表示赞赏，提醒看升旗要早点去占好位置且冬天需多穿保暖衣物，并询问人类是只打算看升旗还是看完升旗后还会去别的地方逛逛。之后人类询问冬天去看升旗会不会很冷，AI回复冬天的北京确实挺冷，尤其是早上看升旗时气温很低，要多备厚羽绒服、保暖帽子、围巾、手套等保暖衣物，还提及若运气好赶上出太阳，中午前后可能会稍微暖和一点，同时再次询问看完升旗之后是否打算再去其他地方逛逛。\"\n",
      "}\n",
      "冬天去北京看升旗的话，人有可能会比较多哦。天安门广场的升旗仪式是很受大家欢迎的景点活动呀，很多游客都会特意早起去观看，感受那份庄严和神圣呢。尤其是节假日期间，人可能会更多一些。所以要是去看升旗的话，最好还是提前做好规划，早点去占个好位置呀。那你看完升旗之后，有想好还要去别的地方逛逛吗？\n",
      "\n",
      "input {\n",
      "  input: \"从深圳过去机票会不会很贵\",\n",
      "  summary: \"人类告知昨天晚上去了北京且玩得很开心，AI热情回应并询问具体地点及有趣经历，人类回复去爬了长城，AI赞叹并进一步询问爬长城时的趣事。随后人类表示计划今年冬天再去一次北京，AI称冬天的北京别有风味，推荐可去看故宫雪景、颐和园结冰的湖面等，还询问人类此次冬天去北京是打算再爬长城还是去其他新地方，以及是否有特别期待在冬天的北京经历的有意思之事。接着人类表示冬天去北京想去看升旗，AI对此表示赞赏，提醒看升旗要早点去占好位置且冬天需多穿保暖衣物，并询问人类是只打算看升旗还是看完升旗后还会去别的地方逛逛。之后人类询问冬天去看升旗会不会很冷，AI回复冬天的北京确实挺冷，尤其是早上看升旗时气温很低，要多备厚羽绒服、保暖帽子、围巾、手套等保暖衣物，还提及若运气好赶上出太阳，中午前后可能会稍微暖和一点，同时再次询问看完升旗之后是否打算再去其他地方逛逛。此后人类询问冬天去看升旗人会不会很多，AI告知冬天去北京看升旗人有可能比较多，天安门广场的升旗仪式很受欢迎，很多游客会特意早起观看，节假日期间人可能更多，提醒要提前做好规划早点去占好位置，并再次询问看完升旗之后是否打算再去其他地方逛逛。\"\n",
      "}\n",
      "从深圳到北京的机票价格会受到很多因素的影响哦，比如出行的具体时间（旺季、淡季、节假日等）、预订的提前量、航空公司以及是否遇到促销活动等等。\n",
      "\n",
      "一般来说，在旅游旺季或者临近节假日的时候，机票价格可能会相对高一些；而如果能提前较长时间预订，比如提前几个月，又或者正好碰上航空公司推出特价机票活动，那价格就会比较实惠啦。你可以多关注一些机票预订平台，设置价格提醒，这样就能及时了解到比较合适的票价情况啦。你这次打算大概什么时候出发去北京看升旗呀？看完升旗之后还是有不少值得一逛的地方呢，比如可以去前门大街感受下老北京的风情哦。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const rst1 = await chatChain.invoke(\"我昨天晚上去了北京，很开心\");\n",
    "console.log(rst1 + '\\n');\n",
    "const rst2 = await chatChain.invoke(\"去爬了长城\");\n",
    "console.log(rst2 + '\\n');\n",
    "const rst3 = await chatChain.invoke(\"我计划今年冬天的时候再去一次\");\n",
    "console.log(rst3 + '\\n');\n",
    "const rst4 = await chatChain.invoke(\"我想去看升旗\");\n",
    "console.log(rst4 + '\\n');\n",
    "const rst5 = await chatChain.invoke(\"会不会很冷\");\n",
    "console.log(rst5 + '\\n');\n",
    "const rst6 = await chatChain.invoke(\"人会不会很多\");\n",
    "console.log(rst6 + '\\n');\n",
    "const rst7 = await chatChain.invoke(\"从深圳过去机票会不会很贵\");\n",
    "console.log(rst7 + '\\n');\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
