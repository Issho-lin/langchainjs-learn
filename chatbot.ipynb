{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8e03a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  OPENAI_API_KEY: \u001b[32m\"sk-b72b74abd3f541a08b68dc756de84958\"\u001b[39m,\n",
       "  MODEL_NAME: \u001b[32m\"qwen-turbo-1101\"\u001b[39m,\n",
       "  BASE_URL: \u001b[32m\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\u001b[39m,\n",
       "  DEEPSEEK_API_KEY: \u001b[32m\"sk-b1a4cf12df35436f972ba72d4e7c669b\"\u001b[39m,\n",
       "  EMBEDDING_MODEL_NAME: \u001b[32m\"text-embedding-v1\"\u001b[39m,\n",
       "  AZURE_OPENAI_API_KEY: \u001b[32m\"923274d2ec144d95b33adad2c29a362e\"\u001b[39m,\n",
       "  AZURE_OPENAI_API_INSTANCE_NAME: \u001b[32m\"gemdalechatgpt4\"\u001b[39m,\n",
       "  AZURE_OPENAI_API_VERSION: \u001b[32m\"2023-07-01-preview\"\u001b[39m,\n",
       "  AZURE_OPENAI_API_DEPLOYMENT_NAME: \u001b[32m\"jdkjkjgpt4turbo\"\u001b[39m,\n",
       "  AZURE_EMBEDDING_MODEL_NAME: \u001b[32m\"text-embedding-ada-002\"\u001b[39m,\n",
       "  SERP_API_KEY: \u001b[32m\"185032b32dc536d633129d221f7f7be48629f0e4569138241d817449166e21ca\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = { env };\n",
    "process.env;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb92f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\n",
    "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "\n",
    "// 加载知识库\n",
    "const loader = new TextLoader(\"documents/chatbot.txt\");\n",
    "const docs = await loader.load();\n",
    "// 切分（超出LLM上下文限制）\n",
    "const splitter = new RecursiveCharacterTextSplitter({\n",
    "  chunkSize: 100,\n",
    "  chunkOverlap: 20,\n",
    "});\n",
    "\n",
    "const splitDocs = await splitter.splitDocuments(docs);\n",
    "\n",
    "// 构建 vector store\n",
    "const embeddings = new OpenAIEmbeddings({\n",
    "  model: process.env.EMBEDDING_MODEL_NAME,\n",
    "  batchSize: 20,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "// const embeddings = new OpenAIEmbeddings({\n",
    "//   configuration: {\n",
    "//     baseURL: `https://${process.env.AZURE_OPENAI_API_INSTANCE_NAME}.openai.azure.com/openai/deployments/${process.env.AZURE_EMBEDDING_MODEL_NAME}`,\n",
    "//     apiKey: process.env.AZURE_OPENAI_API_KEY,\n",
    "//     defaultQuery: {\n",
    "//       \"api-version\": process.env.AZURE_OPENAI_API_VERSION,\n",
    "//     },\n",
    "//   },\n",
    "// });\n",
    "\n",
    "const vectorstore = new MemoryVectorStore(embeddings);\n",
    "await vectorstore.addDocuments(splitDocs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddd8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableSequence } from \"@langchain/core/runnables\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { JSONChatHistory } from \"./node/history/index.ts\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "// // 构建retriever\n",
    "const retriever = vectorstore.asRetriever(2);\n",
    "// const res = await retriever.invoke(\"原文中，谁提出了宏原子的假设？并详细介绍给我宏原子假设的理论\")\n",
    "\n",
    "// console.log(res)\n",
    "\n",
    "// 将获取到的关联上下文处理成纯文字\n",
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  return documents.map((document) => document.pageContent).join(\"\\n\");\n",
    "};\n",
    "\n",
    "const contextRetrieverChain = RunnableSequence.from([\n",
    "  (input) => input.question,\n",
    "  retriever,\n",
    "  convertDocsToString,\n",
    "]);\n",
    "\n",
    "// await contextRetriverChain.invoke({\n",
    "//   question: \"球形闪电\",\n",
    "// });\n",
    "\n",
    "// 构建prompt\n",
    "const TEMPLATE = `\n",
    "你是一个熟知内部知识库的机器人，你在回答时会引用知识库，并擅长通过自己的总结归纳，组织语言给出答案。\n",
    "并且回答时仅根据知识库，尽可能回答用户问题，如果知识库中没有相关内容，你可以回答“原文中没有相关内容”，不要回答知识库以外的内容。\n",
    "\n",
    "以下是知识库中跟用户回答相关的内容：\n",
    "{context}\n",
    "\n",
    "现在，你需要基于知识库，回答以下问题：\n",
    "{question}`;\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromTemplate(TEMPLATE);\n",
    "\n",
    "const llm = new ChatOpenAI({\n",
    "  model: process.env.MODEL_NAME,\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "});\n",
    "// const llm = new ChatOpenAI({\n",
    "//   configuration: {\n",
    "//     baseURL: `https://${process.env.AZURE_OPENAI_API_INSTANCE_NAME}.openai.azure.com/openai/deployments/${process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME}`,\n",
    "//     apiKey: process.env.AZURE_OPENAI_API_KEY,\n",
    "//     defaultQuery: {\n",
    "//       \"api-version\": process.env.AZURE_OPENAI_API_VERSION,\n",
    "//     },\n",
    "//   },\n",
    "// });\n",
    "\n",
    "// function getContext(question: string) {\n",
    "//   console.log(question)\n",
    "//   return '球形闪电是一种面包'\n",
    "// }\n",
    "\n",
    "\n",
    "const history = new JSONChatHistory({\n",
    "  dir: \"chat_data\",\n",
    "  sessionId: \"chatbot\",\n",
    "})\n",
    "\n",
    "const memory = new BufferMemory({ chatHistory: history });\n",
    "\n",
    "const ragChain = RunnableSequence.from([\n",
    "  // RunnableParallel.from({\n",
    "  //     context: contextRetrieverChain,\n",
    "  //     question: (input) => input.question,\n",
    "  // }),\n",
    "  // async (input) => ({\n",
    "  //   context: await contextRetrieverChain.invoke({ question: input.question }),\n",
    "  //   question: input.question\n",
    "  // }),\n",
    "  {\n",
    "    context: async (input) => {\n",
    "      const context = await contextRetrieverChain.invoke({ question: input.question });\n",
    "      console.log('context------', context)\n",
    "      return context\n",
    "    },\n",
    "    // context: contextRetrieverChain,\n",
    "    question: (input) => input.question,\n",
    "  },\n",
    "  prompt,\n",
    "  llm,\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "// const chain = new ConversationChain({ llm: ragChain, memory });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3994c5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context------ 洁，像新的一样，脸色有些苍白，但目光清澈而平静。她最后在父亲面前站住了。\n",
      "我们认识，她就是许多年前在深夜的大学图书馆里说我很有目的性并问我在找什么的那位漂亮女生，我想了半天才想起她的名字：戴琳。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"叶文洁是脸色有些苍白，但目光清澈而平静的一个人物。她是许多年前在深夜的大学图书馆里与“我”有过交谈的那位女性，被描述为漂亮的女生，并且曾经对“我”说很有目的性并询问“我”在找什么。后来，“我”想起了她的名字叫戴琳。因此，叶文洁就是指戴琳。请注意，知识库中并没有直接提到“叶文洁”这个名字，而是通过描述和后续的信息关联到了戴琳。\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ragChain.invoke({\n",
    "  question: \"叶文洁是什么人\",\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
